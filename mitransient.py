# -*- coding: utf-8 -*-
"""mitransient

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19GT22CckZ1veNb3LMOEjkXaaT5oG_i-3
"""

!pip install mitransient
import mitsuba as mi
mi.set_variant('scalar_rgb') #Hay que definir una variable antes de importar mitransient
import mitransient as mitr

"""Integrators: Los integradores son un parametro del renderizado que nos determina como se va a propagar la luz indirectamente en una escena y también es un parametro para cuando se va a reconstruir la escena

En la guia de mitransient se proponen 3, que son los mas conocidos

Transient path(Ruta transistoria): es un algoritmo estandar que incluye la dimension temporal, este simula como los fotones viajan en la escena, es clave para simular la dispersión

  Los parametros son:

  camera_unwrap= Si es Verdadero, no se tiene en cuenta la distancia desde el origen de la cámara hasta el primer punto de intersección del rayo de la cámara. Esto le permite ver el video transitorio con los eventos que suceden en tiempo mundial. Si es Falso, se tiene en cuenta esta distancia, por lo que ve lo mismo que vería con una cámara ultrarrápida del mundo real. (predeterminado: falso)

  temporal_filter= Puede tener valor 'box' para un filtro sin parametros, 'gaussian' para un filtro gaussiano(MEJORAR INFORMACION DE ESTA PARTE)

  gaussian_sttdev= Cuando es 'gaussian' marca la desviación estándar del filtro gaussiano (valor predeterminado: 2.0)

  block_size= Tamaño de los bloques de imagen

  max_depth= Especifica la profundidad de la ruta más larga en la imagen de salida generada

  rr_depth= Especifica la profundidad de la ruta en la que la implementación comenzará a utilizar el criterio de terminación de ruta

"""

import os
scene = mi.load_file(os.path.abspath('/content/cbox_volumetric.xml'))

transient_integrator = scene.integrator() #Inicializa el integrador
transient_integrator.prepare_transient(scene, sensor=0) #Sensor=0 indica que es el primer sensor
data_steady, data_transient = transient_integrator.render(scene, spp=1024) #Renderiza la escena usando 1024 samples per pixel (spp) para mejorar la calidad
print(data_steady.shape, data_transient.shape)

mi.util.convert_to_bitmap(data_steady) #Para mostrar la imagen :D

# Para ponerlo en videito uwu
import numpy as np

data_transient_tonemapped = mitr.vis.tonemap_transient(
    np.moveaxis(data_transient, 0, 1)
)

mitr.vis.show_video(
    data_transient_tonemapped,
    axis_video=2,
)